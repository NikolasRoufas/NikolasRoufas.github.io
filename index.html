
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Nikolaos Roufas | AI Researcher</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Nikolaos Roufas" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://Nikolaosroufas.me" />
<meta property="og:url" content="http://Nikolaosroufas.me" />
<meta property="og:site_name" content="Nikolaos Roufas" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Nikolaos Roufas" />
<link rel="icon" type="image/x-icon" href="favicon.ico">


<script async src="https://www.googletagmanager.com/gtag/js?id=G-45L4TRSCVZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-45L4TRSCVZ');
</script>

<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Nikolaos Roufas",
    "url": "https://nikolaosroufas.me",
    "sameAs": [
      "https://github.com/NikolasRoufas",
      "https://gr.linkedin.com/in/nikolaosroufas",
      "https://scholar.google.com/citations?user=7fCD268AAAAJ&hl=en&oi=ao",
      "https://orcid.org/0009-0005-6139-743X"
    ],
    "jobTitle": "AI Researcher",
    "worksFor": {
      "@type": "EducationalOrganization",
      "name": "Ionian University"
    },
    "alumniOf": {
      "@type": "EducationalOrganization",
      "name": "Ionian University"
    },
    "knowsAbout": [
      "Artificial Intelligence",
      "Machine Learning",
      "Deep Learning",
      "Natural Language Processing",
      "Quantum Computing"
    ],
    "image": "https://nikolaosroufas.me/1723555068742-4.jpeg"
  }
  </script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="stylesheets/styles.css">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper" style="text-align: justify;">
      <header>
        <h1><a href="http://Nikolaosroufas.me">Nikolaos Roufas</a></h1>
        
        
          <img src="/1723555068742-4.jpeg" alt="Nikolaos" height="230" />
        

        <p></p>

        

        

        
        
        <p>nikolaosroufas@gmail.com   inf2024146@ionio.gr<br>
        <a href="http://nikolaosroufas.me/NikolaosRoufas_CV.pdf">Curriculum Vitae</a><br>
        <a href="https://scholar.google.com/citations?user=7fCD268AAAAJ">Google Scholar</a><br>
        <a href="https://github.com/nikolasroufas">GitHub</a><br>
        <a href="https://www.linkedin.com/in/nikolaosroufas/">LinkedIn</a></p>
        <a href="https://medium.com/@nikolaosroufas/the-impact-of-vibe-coders-on-the-tech-market-a-comprehensive-analysis-96613a15d937">Medium</a></p>
      </header>
      <section>

      <p> </p>

<p> </p>

<p style="text-align: justify">
I’m an undergraduate Computer Science student at the <strong>Ionian University</strong>, Department of Informatics, conducting research in <strong>Neural Networks</strong>, <strong>Machine Learning</strong>, and <strong>Explainable AI (XAI)</strong>. 
As part of the <strong>Erasmus+ program</strong>, I’m currently a visiting research student at <strong>Sapienza University of Rome</strong>, focusing on <em>Self-Explainable Neural Networks (SENN)</em> and interpretability in large-scale social data models.
</p>

<p style="text-align: justify">
My research is driven by a central question: <em>How can we design neural systems that are both powerful and interpretable?</em> 
I explore architectures that balance high performance with transparency—bridging modern deep learning with principles of interpretability, modularity, and human-aligned reasoning.
</p>

<p style="text-align: justify">
I work with <strong>transformer-based architectures</strong>, <strong>semantic retrieval pipelines</strong>, and <strong>explainability methods</strong> such as LID-based interpretability and attention visualization. 
My projects span <em>social discourse analysis</em>, <em>legal AI</em>, and <em>scientific text understanding</em>, with growing interests in <strong>quantum-enhanced ML</strong> and reproducible, modular AI design.
</p>

<p style="text-align: justify">
I have co-authored multiple peer-reviewed papers published in venues such as <em>Springer</em>, <em>Frontiers in Artificial Intelligence</em>, and <em>IEEE</em>. 
Becoming one of the youngest Greek researchers to present at <strong>AIAI 2025</strong>, I continue to work toward explainable and efficient neural architectures that advance responsible AI. 
My long-term goal is to pursue a Ph.D. in Artificial Intelligence—potentially at institutions such as <strong>ETH Zurich</strong>—and contribute to transparent and interpretable machine learning systems.
</p>

<hr />

<h1 id="research">Research</h1>

<p align="center">
  <img src="Ionian-University-logo-2.gif" alt="Ionian University Logo" height="80px" style="margin-right: 20px;" />
  <img src="Sapienza-Logo.png" alt="Sapienza University of Rome Logo" height="80px" />
</p>

<p style="text-align: justify">
My research focuses on the design and analysis of <strong>neural architectures</strong> for <strong>interpretable AI</strong>. 
Current directions include:
</p>

<ul>
  <li><strong>Explainable NLP</strong> — developing transformer-based models for understanding social and climate discourse through sentiment and semantic structure analysis.</li>
  <li><strong>Legal AI</strong> — building GDPR-compliant text anonymization systems and <em>domain-adapted transformers</em> for named-entity recognition in legal contexts.</li>
  <li><strong>Scientific & Quantum ML</strong> — exploring <em>Performer architectures</em> for protein folding and hybrid quantum–classical pipelines using <strong>Qiskit</strong>.</li>
  <li><strong>Neural Interpretability</strong> — analyzing layer-wise information decomposition and feature attribution methods for self-explainable networks (SENN).</li>
</ul>

<p align="center">
  <a href="https://github.com/NikolasRoufas">
    <img align="center" src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" 
         alt="GitHub Logo" height="33px" />
  </a>
</p>

<hr />

<h1 id="papers">Papers</h1>

<p style="text-align: justify">
<strong><span style="font-size:11pt;">Analyzing Public Discourse and Sentiment in Climate Change Discussions Using Transformer-Based Models</span></strong><br />
<ins>N. Roufas</ins>, A. Mohasseb, I. Karamitsos & A. Kanavos*<br />
<strong>IFIP AIAI 2025</strong> | <a href="https://link.springer.com/chapter/10.1007/978-3-031-97313-0_4">paper</a>
</p>

<p style="text-align: justify">
<strong><span style="font-size:11pt;">LegNER: A Domain-Adapted Transformer for Legal Named Entity Recognition and Text Anonymization</span></strong><br />
<ins>N. Roufas</ins>, I. Karamitsos, K. Al-Hussaeni & A. Kanavos*<br />
<strong>Frontiers in Artificial Intelligence, 2025</strong> | <a>In press</a>
</p>

<p style="text-align: justify">
<strong><span style="font-size:11pt;">Efficient Protein Folding with Transformer Models Using the Performer Architecture</span></strong><br />
<ins>N. Roufas</ins>, I. Karamitsos, K. Al-Hussaeni, V. C. Gerogiannis & A. Kanavos*<br />
<strong>ICTA 2025</strong> | <a>In press</a>
</p>

<p style="text-align: justify">
<strong><span style="font-size:11pt;">Do Deeper Layers Explain Better? An LID-Based Study of Transformer Explainability</span></strong><br />
<ins>N. Roufas</ins>, A. Kanavos, I. Karamitsos, K. Al-Hussaeni & M. Maragoudakis*<br />
<strong>IEEE AdHD Big Data Workshop 2025</strong> | <a>In press</a>
</p>

<hr />

<p><em>Last Update: October 2025</em></p>




      </section>
      <footer>
        
        <p><small>Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>

  </body>
</html>
